
\section{Experiments}
In this section, the details of training road embeddings by the next-hop prediction model will be given. And we will explain the process of parameter tuning. A verification for the functionality of road correlation, as well as an analysis and visualization are also stated in this section.

\subsection{Settings}
Our experiments were performed on a sever equipped with Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz and an NVIDIA GeForce RTX 2080Ti graphics card. The PyTorch\cite{pytorch} version is 1.7.1 with Python 3.7.11.

For the next-hop prediction model, the window size for trajectory fragments generation was set as $w=5$. After data processing, we got 1,751,602 trajectories in total. Removing too long and too short ones, there were 1,351,700 remaining. Then we put the trajectories into 24 bins according to their starting time and randomly sampled $p=80\%$ data in each bin to combine as the whole dataset. Finally, there were 1,076,886 trajectories. The data ratio for training, validation, and testing was set as 7:1:2. After window sliding, we got 10,228,578 trajectory fragments for training, and 1,455,100 for validation. Adam\cite{adam} algorithm was employed to control the overall training process, and the loss function was \textit{Cross Entropy Loss}. The complete parameter selection is given in table \ref{next-hop_params}.

\begin{table}[htb]
    \begin{center}
        \caption{Tuned parameters for next-hop prediction.}
        \label{next-hop_params}
        \begin{tabular}{clll}
            \toprule
  
            \textbf{Notation} & \textbf{Parameter} & \textbf{Search Space} & \textbf{Selected Value}\\
  
            \midrule
  
            $w$ & Window size & $\{5 \}$ & $5$\\
            $p$ & Sampling proportion & $\{0.05, 0.1, 0.2, 0.4, 0.8\}$ & $0.8$\\
            $d_r$ & Road embedding dimension & $\{16, 32, 64, 128 \}$ & $64$\\
            $d_h$ & LSTM hidden size & $\{32, 64, 128, 256 \}$ & $256$\\
            $d_o$ & Linear output dimension & $d_o=n_r=\#roads$ & $492$\\
            ~ & Batch size & $\{64, 128, 256, 512 \}$ & $256$\\
            ~ & Learning rate & $\{0.0001, 0.001\}$ & $0.0001$\\
            ~ & Early stopping epochs & $\{5, 10, 15\}$ & $10$\\
  
            \bottomrule
        \end{tabular}
    \end{center}
\end{table}

For traffic state prediction model, the input steps and prediction steps were both set to 12. The size of traffic state matrix is $n_r\times n_t=492\times 8064$. The data split ratio was also 7:1:2, and after sampling, we got 6437 traffic state vectors for training. The optimizer was Adam where the learning rate was set as 0.001, and the loss function was \textit{Mean Squared Error (MSE) Loss}. Batch size was set to 32 in order to avoid the \textit{CUDA Out of Memory} exception. Similarly, the training process would be early-stopped if the validation loss was not decreasing for 10 epochs, then the best model on validation data would be saved. Details are provided in table \ref{traff_pred_params}.

\begin{table}[htb]
    \begin{center}
        \caption{Parameters for traffic state prediction.}
        \label{traff_pred_params}
        \begin{tabular}{cll}
            \toprule
  
            \textbf{Notation} & \textbf{Parameter} & \textbf{Value}\\
  
            \midrule
  
            $w_{in}$ & Input steps & $12$\\
            $w_{out}$ & Prediction steps & $12$\\
            ~ & Batch size & $32$\\
            ~ & Learning rate & $0.001$\\
            ~ & Early stopping epochs & $10$\\
            ~ & Max training epochs & $200$\\
  
            \bottomrule
        \end{tabular}
    \end{center}
\end{table}

\subsection{Baseline Models}
We selected two baseline traffic prediction models that can effectively capture the spatial dependencies in the graph.

\begin{itemize}
    \item \textbf{STGCN}\cite{STGCN} (Spatio-Temporal Graph Convolutional Networks). STGCN is proposed in 2018, which is one of the earliest GCN models for traffic prediction. It uses gated TCN\cite{TCN} to capture temporal dependencies and applies spectral graph convolution\cite{GCN0} on graph to model the spatial dependencies.
    \item \textbf{DCRNN}\cite{DCRNN} (Diffusion Convolutional Recurrent Neural Network). DCRNN is another typical GCN model that is also proposed in 2018. Instead of spectral graph convolution, it implements diffusion convolution through bidirectional random walk to capture the transition information. Temporally, it integrates diffusion convolution into GRU and proposed an encoder-decoder structure to enable multi step prediction.
\end{itemize}

We set the input graph as (1) adjacency matrix $A$, (2) refined adjacency matrix $A'$ to compare their performance and illustrate the effect of road correlation in traffic state prediction. The corresponding models are denoted as STGCN@$A$, STGCN@$A'$, DCRNN@$A$ and DCRNN@$A'$.

\subsection{Evaluation Metrics}
Following previous studies, we use \textit{Root Mean Square Error (RMSE)}, \textit{Mean Absolute Error (MAE)}, and \textit{Mean Absolute Percentage Error (MAPE)} as the metrics to show performance of different methods. Zero values will be ignored. The definition of them are as following.

\subsection{Overall Performance}
主要放 Performance table
以及一些分析

\subsection{Parameter Study}
embedding 模型的调参图
knn 的调参图

\subsection{Road Correlation Analysis}
可解释
画道路图
