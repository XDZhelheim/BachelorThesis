
\section{Experiments}
In this section, the details of training road embeddings by the next-hop prediction model will be given. And we will explain the process of parameter tuning. A verification for the functionality of road correlation, as well as an analysis and visualization are also stated in this section.

\subsection{Settings}
Our experiments were performed on a sever equipped with Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz and an NVIDIA GeForce RTX 2080Ti graphics card. The PyTorch\cite{pytorch} version is 1.7.1 with Python 3.7.11.

For the next-hop prediction model, the window size for trajectory fragments generation was set as $w=5$. After data processing, we got 1,751,602 trajectories in total. Removing too long and too short ones, there were 1,351,700 remaining. Then we put the trajectories into 24 bins according to their starting time and randomly sampled $p=80\%$ data in each bin to combine as the whole dataset. Finally, there were 1,076,886 trajectories. The data ratio for training, validation, and testing was set as 7:1:2. After window sliding, we got 10,228,578 trajectory fragments for training, and 1,455,100 for validation. Adam\cite{adam} algorithm was employed to control the overall training process, and the loss function was \textit{Cross Entropy Loss}. The complete parameter selection is given in table \ref{next-hop_params}.

\begin{table}[htb]
    \begin{center}
        \caption{Tuned parameters for next-hop prediction.}
        \label{next-hop_params}
        \begin{tabular}{clll}
            \toprule
  
            \textbf{Notation} & \textbf{Parameter} & \textbf{Search Space} & \textbf{Selected Value}\\
  
            \midrule
  
            $w$ & Window size & $\{5 \}$ & $5$\\
            $p$ & Sampling proportion & $\{0.05, 0.1, 0.2, 0.4, 0.8\}$ & $0.8$\\
            $d_r$ & Road embedding dimension & $\{16, 32, 64, 128 \}$ & $64$\\
            $d_h$ & LSTM hidden size & $\{32, 64, 128, 256 \}$ & $256$\\
            $d_o$ & Linear output dimension & $d_o=n_r=\#roads$ & $492$\\
            ~ & Batch size & $\{64, 128, 256, 512 \}$ & $256$\\
            ~ & Learning rate & $\{0.0001, 0.001\}$ & $0.0001$\\
            ~ & Early stopping epochs & $\{5, 10, 15\}$ & $10$\\
  
            \bottomrule
        \end{tabular}
    \end{center}
\end{table}

For traffic state prediction model, the input steps and prediction steps were both set to 12. The size of traffic state matrix is $n_r\times n_t=492\times 8064$. The data split ratio was also 7:1:2, and after sampling, we got 6437 traffic state vectors for training. The optimizer was Adam where the learning rate was set as 0.001, and the loss function was \textit{Mean Squared Error (MSE) Loss}. Batch size was set to 32 in order to avoid the \textit{CUDA Out of Memory} exception. Similarly, the training process would be early-stopped if the validation loss was not decreasing for 10 epochs, then the best model on validation data would be saved. Details are provided in table \ref{traff_pred_params}.

\begin{table}[htb]
    \begin{center}
        \caption{Parameters for traffic state prediction.}
        \label{traff_pred_params}
        \begin{tabular}{cll}
            \toprule
  
            \textbf{Notation} & \textbf{Parameter} & \textbf{Value}\\
  
            \midrule
  
            $w_{in}$ & Input steps & $12$\\
            $w_{out}$ & Prediction steps & $12$\\
            ~ & Batch size & $32$\\
            ~ & Learning rate & $0.001$\\
            ~ & Early stopping epochs & $10$\\
            ~ & Max training epochs & $200$\\
  
            \bottomrule
        \end{tabular}
    \end{center}
\end{table}

\subsection{Baseline Models}
We selected two baseline traffic prediction models that can effectively capture the spatial dependencies in the graph.

\begin{itemize}
    \item \textbf{STGCN}\cite{STGCN} (Spatio-Temporal Graph Convolutional Networks). STGCN is proposed in 2018, which is one of the earliest GCN models for traffic prediction. It uses gated TCN\cite{TCN} to capture temporal dependencies and applies spectral graph convolution\cite{GCN0} on graph to model the spatial dependencies.
    \item \textbf{DCRNN}\cite{DCRNN} (Diffusion Convolutional Recurrent Neural Network). DCRNN is another typical GCN model that is also proposed in 2018. Instead of spectral graph convolution, it implements diffusion convolution through bidirectional random walk to capture the transition information. Temporally, it integrates diffusion convolution into GRU and proposed an encoder-decoder structure to enable multistep prediction.
\end{itemize}

We set the input graph as (1) \textit{adjacency matrix} $A$, (2) \textit{refined adjacency matrix} $A'$ to compare their performance and illustrate the effect of road correlation in traffic state prediction. The corresponding models are denoted as STGCN-$A$, STGCN-$A'$, DCRNN-$A$ and DCRNN-$A'$. In addition, we kept the (3) \textit{road correlation matrix} $C$ as input to give an ablation experiment. They are denoted as STGCN-$C$ and DCRNN-$C$.

\subsection{Evaluation Metrics}
Following previous studies, we use \textit{Root Mean Square Error (RMSE)}, \textit{Mean Absolute Error (MAE)}, and \textit{Mean Absolute Percentage Error (MAPE)} as the metrics to show performance of different methods. Zero values will be ignored, and lower errors indicate better performance. The definition of them are as following.

\begin{equation}
    \begin{aligned}
        MAE&=\frac 1n\sum_{i=1}^n|\hat{y_i}-y_i|\\
        MAPE&=\frac 1n\sum_{i=1}^n|\frac{\hat{y_i}-y_i}{y_i}|\\
        RMSE&=\sqrt{\frac 1n\sum_{i=1}^n(\hat{y_i}-y_i)^2}
    \end{aligned}
\end{equation}

\subsection{Overall Performance}
First we introduce the performance of next-hop prediction. We tried tens of parameter combinations and finally reached $5.47$ test loss and $73.47\%$ prediction accuracy. The embedding matrix $E$ in the model was saved for the computation of \textit{refined adjacency matrix} $A'$. Then the comparison of the four models' performance are given in table \ref{performance_results}. To demonstrate how the prediction accuracy varies with time, we report the metrics for 15, 30, 60-minutes ahead prediction. From the table, we obtain the following observations:

\begin{table}[htb]
    \renewcommand\arraystretch{1.5} % 1.5 line space
    \begin{center}
        \caption{Performance evaluation results.}
        \label{performance_results}
        \resizebox{\textwidth}{!}{
            \begin{tabular}{c|c|ccc|ccc|ccc}
                \toprule

                \multirow{2}{*}{\textbf{Traffic State}} & \multirow{2}{*}{\textbf{Model}} & \multicolumn{3}{c|}{\textbf{3 Steps / 15 min}} & \multicolumn{3}{c|}{\textbf{6 Steps / 30 min}} & \multicolumn{3}{c}{\textbf{12 Steps / 60 min}}\\
                \cline{3-11}
                ~ & ~ & \textit{RMSE} & \textit{MAE} & \textit{MAPE} & \textit{RMSE} & \textit{MAE} & \textit{MAPE} & \textit{RMSE} & \textit{MAE} & \textit{MAPE}\\

                \hline

                \multirow{6}{*}{Flow} & STGCN-$A$ & $4.44$ & $3.46$ & $33.00\%$ & $4.64$ & $3.57$ & $33.64\%$ & $5.07$ & $3.88$ & $36.07\%$\\
                ~ & STGCN-$C$ & $4.38$ & $3.40$ & $32.41\%$ & $\mathbf{4.56}$ & $\mathbf{3.52}$ & $33.33\%$ & $5.03$ & $3.82$ & $35.87\%$\\
                ~ & STGCN-$A'$ & $4.43$ & $3.43$ & $32.52\%$ & $4.59$ & $3.53$ & $\mathbf{33.23}\%$ & $4.98$ & $3.78$ & $35.31\%$\\
                ~ & DCRNN-$A$ & $4.47$ & $3.46$ & $33.01\%$ & $4.66$ & $3.60$ & $34.06\%$ & $5.03$ & $3.85$ & $35.76\%$\\
                ~ & DCRNN-$C$ & $8.19$ & $6.13$ & $55.66\%$ & $8.18$ & $6.13$ & $55.64\%$ & $8.13$ & $6.09$ & $55.33\%$\\
                ~ & DCRNN-$A'$ & $\mathbf{4.23}$ & $\mathbf{3.28}$ & $\mathbf{31.46\%}$ & $4.63$ & $3.54$ & $33.60\%$ & $\mathbf{4.98}$ & $\mathbf{3.77}$ & $\mathbf{35.26\%}$\\

                \hline

                \multirow{6}{*}{Speed} & STGCN-$A$ & $6.60$ & $4.65$ & $23.67\%$ & $6.63$ & $4.66$ & $24.22\%$ & $6.71$ & $4.74$ & $24.01\%$\\
                ~ & STGCN-$C$ & $6.62$ & $4.66$ & $23.87\%$ & $6.63$ & $4.69$ & $24.10\%$ & $6.67$ & $\mathbf{4.71}$ & $24.04\%$\\ 
                ~ & STGCN-$A'$ & $\mathbf{6.60}$ & $\mathbf{4.65}$ & $\mathbf{23.66\%}$ & $\mathbf{6.62}$ & $\mathbf{4.67}$ & $\mathbf{23.79\%}$ & $\mathbf{6.67}$ & $4.72$ & $\mathbf{24.00\%}$\\
                ~ & DCRNN-$A$ & $6.61$ & $4.65$ & $23.82\%$ & $6.65$ & $4.69$ & $24.00\%$ & $6.71$ & $4.76$ & $24.29\%$\\
                ~ & DCRNN-$C$ & $8.41$ & $6.39$ & $30.90\%$ & $8.45$ & $6.42$ & $31.13\%$ & $8.46$ & $6.43$ & $31.18\%$\\
                ~ & DCRNN-$A'$ & $6.62$ & $4.65$ & $23.82\%$ & $6.66$ & $4.68$ & $23.99\%$ & $6.71$ & $4.75$ & $24.25\%$\\

                \bottomrule
            \end{tabular}
        }
    \end{center}
\end{table}

\begin{itemize}
    \item 
\end{itemize}

\subsection{Parameter Study}
embedding 模型的调参图
knn 的调参图

\subsection{Road Correlation Analysis}
可解释
画道路图
